{"subjectName":"IT","subjectDescription":"IT is one of our most popular categories, with in-depth courses and tutorials across all aspects of information technology. Sign up today to learn about cryptocurrency, blockchain, computer networking and server management. You can take free classes for in-demand languages like Python, JavaS... Read more...","subjectBg":"https://cdn01.alison-static.net/search/header-img/it.jpg","resumeLink":"https://alison.com/resume/courses/3643","title":"Basics of Hadoop","totalEnrolled":"461","courseIncludes":["1.5-3 Hours of Learning","CPD Accreditation","Final Assessment"],"headline":"Understand the basics of the Apache Hadoop ecosystem with hands-on exercises in this free analytics training course.","description":"In this short course, you will be introduced to the components and tools of Apache Hadoop. Learn how to store and process large datasets ranging in size from gigabytes to petabytes with big data. The HDFS (Hadoop distributed file system) architecture, data processing using MapReduce, and importing and exporting data using SQOOP will be covered. The course also has a section that provides you with practical knowledge and hands-on activities.","courseOutcomes":["Discuss the overview of Apache Hadoo...","List the top commercial Hadoop vendo...","Explain the HDFS (Hadoop distributed...","Describe dataflow using MapReduce...","Discuss the overview of Apache Hadoop","List the top commercial Hadoop vendors","Explain the HDFS (Hadoop distributed file system) architecture","Describe dataflow using MapReduce","Explain how to export data from RDBMS (relational database management system) to Hive","Summarise the SQOOP process","Differentiate between Hive and Impala to RDBMS","Explain how to create different Pig Latin scripts, execute and use different functions to perform ETL (extract, transform and load)","Analyze Oozie parameters","Discuss the overview of Apache Hadoo...","List the top commercial Hadoop vendo...","Explain the HDFS (Hadoop distributed...","Describe dataflow using MapReduce...","Discuss the overview of Apache Hadoop","List the top commercial Hadoop vendors","Explain the HDFS (Hadoop distributed file system) architecture","Describe dataflow using MapReduce","Explain how to export data from RDBMS (relational database management system) to Hive","Summarise the SQOOP process","Differentiate between Hive and Impala to RDBMS","Explain how to create different Pig Latin scripts, execute and use different functions to perform ETL (extract, transform and load)","Analyze Oozie parameters"],"courseDescription":"<p>Apache Hadoop is an open-source software framework that facilitates the use of a network of computer devices to store and process large data sets using simple programming models. It is designed to solve problems that involve analyzing large amounts of data ranging from gigabytes to petabytes (one million gigabytes). The framework is written in Java and is based on Googleâ€™s MapReduce programming model. This course begins with an introduction to Hadoop and big data software utility. It will teach you the features, types, and sources of information in big data. The various ways of analyzing big data and its benefits will also be covered. An overview of Apache Hadoop, its framework, history, and the Hadoop ecosystem will be discussed. Then, in the practice section, you will study how to download, start and connect to the Cloudera virtual machine using the Docker platform. Furthermore, you will study the architecture of the Hadoop distributed file system (HDFS). The building blocks of Hadoop, its components and workflow will be explained. Also, some useful HDFS shell commands used to manage files on the HDFS clusters and how to create directories, move, delete and read files will be highlighted.</p><p>Next, you will be introduced to MapReduce, studying its architecture and seeing how it works. You will also learn about the data flow of MapReduce, YARN (Yet Another Resource Negotiator) architecture, and the differences between traditional relational database management systems (RDBMS) and MapReduce. Thereafter, you will be taught the architecture of SQOOP and how to import and export data using the SQOOP command-line interface. The syntax for importing data from RDBMS to HDFS and from RDBMS to Hive through SQOOP import and exporting data from HDFS to RDBMS and from HIVE to RDBMS through SQOOP export will be explained in two practice sections. Then, you will study Hive, its architecture, components and data types. The types of tables in Hive, the Hive schema, and data storage will be highlighted. Furthermore, the Impala MPP SQL query engine, its features, and the differences between Impala, Hive, and the traditional RDBMS database will be considered. Also, creating external Hive tables, creating managed Hive tables, and running HQL and Impala queries for analyzing the data will be covered in the practice section.</p><p>Next, you will study Pig scripting in Hadoop. You will learn the Pig data types, their uses, and how Pig scripts are executed with the engine. How to load data into Pig as well as filtering data will be also be explained. Creating different Pig Latin scripts, executing and using different functions to perform ETL (extract, transform and load) using Pig will be outlined in the practice section. Then, you will be introduced to the Oozie workflow scheduling system to manage Hadoop jobs. The types of jobs in Oozie, its architecture, features, and actions will be reviewed. Oozie parameterization and how the flow control in the Oozie workflow operates will be critically analyzed. In the practice section, you will learn how to create different actions in SQOOP, Hive, and Pig. This course is for database and data house developers, big data developers, data analysts, and any technical personnel who are interested to learn and explore the various features of Hadoop and its tools. What keeps you waiting? Enroll now and start learning today!</p><a href=\"https://alison.com/resume/courses/3643\" class=\"l-but course_btn\">Start Course Now</a>","certificateDetail":"<p> All Alison courses are free to enrol study and complete. To successfully complete this <span class=\"course-type\">certificate</span> course and become an Alison Graduate, you need to achieve 80% or higher in each course assessment. Once you have completed this <span class=\"course-type\">certificate</span> course, you have the option to acquire an official Diploma, which is a great way to share your achievement with the world. </p><div class=\"l-list l-list--tick\"><h6>Your Alison <span class=\"course-type\">certificate</span> is:</h6><ul><li>Ideal for sharing with potential employers</li><li>Include it in your CV, professional social media profiles and job applications.</li><li>An indication of your commitment to continuously learn, upskill &amp; achieve high results.</li><li>An incentive for you to continue empowering yourself through lifelong learning.</li></ul></div><hr><div class=\"l-flex l-flex--even\"><div class=\"l-list l-list--bullet\"><h6>Alison offers <span class=\"l-list__color\">3 types</span> of Diplomas for completed Diploma courses:</h6><ul><li><strong>Digital <span class=\"course-type\">certificate</span>:</strong> a downloadable <span class=\"course-type\">certificate</span> in PDF format immediately available to you when you complete your purchase. </li><li><strong><span class=\"course-type\">certificate</span>:</strong> a physical version of your officially branded and security-marked <span class=\"course-type\">certificate</span>, posted to you with FREE shipping. </li><li><strong>Framed <span class=\"course-type\">certificate</span>:</strong> a physical version of your officially branded and security marked <span class=\"course-type\">certificate</span> in a stylish frame, posted to you with FREE shipping. </li></ul></div><div class=\"l-diploma\"><img class=\"lazyload\" data-src=\"https://cdn01.alison-static.net/public/html/site/img/course-landing-v2/diploma.png\"><a class=\"course_btn course_btn--alt\" href=\"https://alison.com/resume/courses/3643\">Start Course Now <span class=\"icon-thick-chevron-down right\"></span></a></div></div><p> All <span class=\"course-type\">certificate</span> are available to purchase through the <a href=\"https://alison.com/shop\">Alison Shop</a>. For more information on purchasing Alison <span class=\"course-type\">certificate</span>, please visit our <a href=\"https://alison.com/faqs\">FAQs</a>. If you decide not to purchase your Alison <span class=\"course-type\">certificate</span>, you can still demonstrate your achievement by sharing your Learner Record or Learner Achievement Verification, both of which are accessible from your <a href=\"https://alison.com/dashboard\">Dashboard</a>. For more details on our <span class=\"course-type\">certificate</span> pricing, please visit our <a href=\"https://alison.com/about/pricing\">Pricing Page</a></p>","modules":[{"name":"Module","details":"Hadoop Components and Tools","description":"In this module, you will be introduced to Apache Hadoop and its components. You will learn the HDFS architecture and perform data processing using MapReduce. Importing and exporting data using SQOOP, as well as creating and executing Pig Latin scripts to perform ETL will be explained. Also, how to create and use the Oozie workflow will be covered.","topics":["Hadoop Components and Tools - Learning Outcomes","Introduction","Introduction to BigData","Architecture of HDFS","Map Reduce (MR)","Understanding SQOOP","Hive and Impala","Understanding Pig","Introduction to Oozie","Hadoop Components and Tools - Lesson Summary"]},{"name":"Module","details":"Course assessment","description":"","topics":["Fundamentals of Hadoop - Course Assessment"]}]}